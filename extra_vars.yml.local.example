#######################
# These are required. #
#######################

#
# SUSE Product Registrion Information. Make sure the registration is activated
# in https://scc.suse.com
#
#registration_email: <your SCC registration email here>

#
# SLE Micro product registration code
#
#sle_micro_registration_code: INTERNAL-USE-ONLY-blah-blah

#
# SLES product registration code
#
#sles_registration_code: INTERNAL-USE-ONLY-yada-yada

#
# Your github username
#
github_username: <your github username>

#
# SUSE Okta B2C -> Application Collection
# Okta Email
#
application_collection_user_email: <your okta email>

#
# SUSE Okta B2C -> Application Collection
# Application Collection Access Token - https://apps.rancher.io/settings/access-tokens
#
application_collection_user_token: <your application collection access token>

#
# Whether to enable the GPU Operator. Set this to true only if GPU is available.
# i.e. in the case where GPU passthrough is configured via "host_device".
#
enable_gpu_operator: false

#
# Whether to enable time slicing so that multiple pods can share GPU resource
# See https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html#time-slicing-gpus-in-kubernetes
enable_time_slicing: false
time_slicing_replicas: 4


#######################
# These are optional. #
#######################

# Your github personal access token or password, needed to authenticate
# to github in order to access the repo with fleet, if your repo is not public
# and therefore required authentication. This token may be restricted to 
# read-only access to the repository.
#
# NOTE: for security reasons, we don't recommend using your github password.
# Instead, you should create a personal access token for that. See
# https://docs.github.com/en/authentication/
# keeping-your-account-and-data-secure/managing-your-personal-access-tokens
# on how to create a personal access token.
#
#github_token: <your github personal access token or password>

#
# SUSE Open WebUI host name.
#
# NOTE: when using letsEncrypt TLS source. The host name must be a
# fully-qualified domain name, and it must be resolveable via a public DNS.
#
#open_webui_hostname: suse-ollama-webui

#
# Open WebUI admin user display name
#
# Default to "admin"
#
#open_webui_admin_name: admin

#
# Open WebUI admin user email
#
# Default to "admin@suse-private-ai.org"
#
#open_webui_admin_email: admin@suse-private-ai.org

#
#Open WebUI admin password
#
# Default to "WelcomeToAI"
#
#open_webui_admin_password: WelcomeToAI

#
# Whether to enable external-dns.
#
# NOTE: only CloudFlare provider is supported.
#
#enable_external_dns: false

#
# CloudFlare API Token
# 
# NOTE: it is require if enable_external_dns is set to true
#
# cloudflare_api_token: <CloudFlare API Token>

#
# TLS source. Supported values are (case-sensitive) "suse-private-ai",
# "letsEncrypt", and "secret".
#
# NOTE: when using letsEncrypt as source. The DNS record for the WebUI
# endpoint public be public and it must be reacheable from the internet.
#
# By default, the TLS source is "suse-private-ai", which is self-signed
# certificate.
#
#tls_source: suse-private-ai

#
# Indicate whether to use Rancher Prime
#
# Default to true
#
#use_rancher_prime: true

#
# Rancher Prime Helm Chart Repo URL when use_rancher_prime is set to true
#
#rancher_prime_helm_repo_url: ""

#
# Rancher version to use
#
# Default to 2.13.1
#
#rancher_version: 2.13.1

#
# VM user plain text password (not hash)
#
# Default VM user password is 'aiyaya'
#
#vm_user_plain_text_password: aiyaya

# NOTE: this should be *your* (local user) SSH public key since *you*
# will be using it to login to the VMs. The SSH public keys listed
# here will be appended to the VM user's authorized_keys file.
#
vm_authorized_ssh_keys:
  - <your SSH key here>

#
# The virtual network to use.
#
# NOTE: the virtual network exist and running prior to using the private AI
# stack.
#
# Default is libvirt's "default" network.
#
# private_ai_vm_network: default

#
# Static IP address for the VM.
#
# NOTE: you must ensure the static IP, along with the MAC address, are
# properly configured in your virtual network's DHCP setting.
#
# Default is 192.168.122.100.
#
#private_ai_vm_ip: 192.168.122.100

#
# VM MAC address, must be corresponding to the VM static IP
#
# NOTE: make sure the MAC address is assigned to the corresponding
# static IP in the virtual network's DHCP setting.
#
# Default is 52:54:00:6C:3C:88
#
#private_ai_vm_mac_address: 52:54:00:6C:3C:88

###########################################################
# DO NOT modify these unless you know what you are doing! #
###########################################################

#
# Host to VM NIC mapping, determines how to map host NICs to 
# VM NICs. This is the "--network" parameters for virt-install
# when creating the VMs.
#
private_ai_vm_libvirt_network_params: "--network network={{ private_ai_vm_network | default('default') }}"

#
# Host device for GPU Passthrough. This should be the first column from the lspci output.
# For example:
#
# host_device: "04:00.0"
#
# WARNING: make sure you are not sharing this GPU device with other applications on
# on your host (i.e. monitor display) as it will cause problems. Also, make sure the GPU device
# is properly managed by VFIO.
#
#host_device: <device to passthrough>

#
# Flag to control vllm deployment.
# Set this flag to true to deploy vllm.
# The cluster should have at least one GPU node
# and enable_gpu_operator to be true.
#
enable_vllm_deployment: false

#
# Flag to control milvus deployment. When false, it won't be deployed. Default is true
#
enable_milvus: true

#
# Flag to control milvus deployment mode. When false, standalone deployment. When true, cluster deployment
#
enable_milvus_cluster_deployment: true

#
# Flag to control minio deployment mode. When false, distributed deployment. When true, standalone deployment
#
enable_minio_standalone_deployment: false

#
# Flag to control opensearch deployment. When false, it won't be deployed. Default is true
#
enable_opensearch: true

#
# Flag to control opensearch deployment mode. When false, standalone deployment. When true, cluster deployment
#
enable_opensearch_cluster_deployment: true

#
# Install SUSE Observability
#
enable_suse_observability: false

#
# SUSE Observability License
#
suse_observability_license: <your SUSE Observability license>

# Install openwebui pipelines
#
pipelines_enabled: true
